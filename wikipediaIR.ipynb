{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbc2d974",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Wikipedia topics separated by commas (e.g., Natural_language_processing,Python_(programming_language)):\n",
      "Topics: python,C,C++\n",
      "Scraping: https://en.wikipedia.org/wiki/python\n",
      "Scraping: https://en.wikipedia.org/wiki/C\n",
      "Scraping: https://en.wikipedia.org/wiki/C++\n",
      "Scraping complete. Data saved to wikipedia_documents.csv\n",
      "Evaluation Results - Precision: 0.5, Recall: 0.3333333333333333, F1-score: 0.4\n",
      "Enter your search query (or type 'exit' to quit): coding\n",
      "Documents found:\n",
      "- 2: \n",
      " C or c is the third letter of the Latin alphabet, used in the modern English alphabet, the alphabets of other western European languages and others worldwide. Its name in English is cee (pronounced /ˈsiː/), plural cees.[1]\n",
      " \"C\" comes from the same letter as \"G\". The Semites named it gimel. The sign is possibly adapted from an Egyptian hieroglyph for a staff sling, which may have been the meaning of the name gimel. Another possibility is that it depicted a camel, the Semitic name for which was gamal. Barry B. Powell, a specialist in the history of writing, states \"It is hard to imagine how gimel = \"camel\" can be derived from the picture of a camel (it may show his hump, or his head and neck!)\".[2]\n",
      " In the Etruscan language, plosive consonants had no contrastive voicing, so the Greek 'Γ' (Gamma) was adopted into the Etruscan alphabet to represent /k/. Already in the Western Greek alphabet, Gamma first took a '' form in Early Etruscan, then '' in Classical Etruscan. In Latin, it eventua...\n",
      "- 3: \n",
      " C++ (/ˈsiː plʌs plʌs/, pronounced \"C plus plus\" and sometimes abbreviated as CPP) is a high-level, general-purpose programming language created by Danish computer scientist Bjarne Stroustrup. First released in 1985 as an extension of the C programming language, it has since expanded significantly over time; as of 1997[update], C++ has object-oriented, generic, and functional features, in addition to facilities for low-level memory manipulation for systems like microcomputers or to make operating systems like Linux or Windows. It is usually implemented as a compiled language, and many vendors provide C++ compilers, including the Free Software Foundation, LLVM, Microsoft, Intel, Embarcadero, Oracle, and IBM.[14]\n",
      " C++ was designed with systems programming and embedded, resource-constrained software and large systems in mind, with performance, efficiency, and flexibility of use as its design highlights.[15] C++ has also been found useful in many other contexts, with key strengths being s...\n",
      "Enter your search query (or type 'exit' to quit): snake\n",
      "No documents found.\n",
      "Enter your search query (or type 'exit' to quit): exit\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Wikipedia Search Engine Notebook\n",
    "\n",
    "Εισαγωγή\n",
    "Σε αυτό το Notebook, υλοποιούμε μία μηχανή αναζήτησης που βασίζεται σε δεδομένα από τη Wikipedia.\n",
    "Ο κώδικας περιλαμβάνει:\n",
    "1. Συλλογή δεδομένων από τη Wikipedia.\n",
    "2. Επεξεργασία κειμένου και δημιουργία αντιστραμμένου ευρετηρίου.\n",
    "3. Υλοποίηση βασικών λειτουργιών αναζήτησης.\n",
    "4. Αξιολόγηση της μηχανής αναζήτησης.\n",
    "\n",
    "Βιβλιοθήκες και Ρυθμίσεις\n",
    "Εδώ εισάγουμε τις απαραίτητες βιβλιοθήκες για τη συλλογή και επεξεργασία των δεδομένων.\n",
    "Κατεβάζουμε επίσης τα απαραίτητα δεδομένα για την επεξεργασία κειμένου.\"\"\"\n",
    "\n",
    "\n",
    "import csv\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from collections import defaultdict\n",
    "import string\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "\n",
    "# Κατεβάζει τα απαραίτητα δεδομένα για tokenization και stopwords\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "class WikipediaScraper:\n",
    "    \"\"\"Κλάση για συλλογή δεδομένων από την Wikipedia.\"\"\"\n",
    "    \n",
    "    def __init__(self, base_url, csv_file):\n",
    "        \"\"\"\n",
    "        Αρχικοποιεί τη WikipediaScraper.\n",
    "        :param base_url: Η βασική διεύθυνση URL της Wikipedia.\n",
    "        :param csv_file: Το όνομα του αρχείου CSV για αποθήκευση δεδομένων.\n",
    "        \"\"\"\n",
    "        self.base_url = base_url\n",
    "        self.csv_file = csv_file\n",
    "\n",
    "    def scrape(self, topic_list):\n",
    "        \"\"\"\n",
    "        Συλλέγει άρθρα από τη Wikipedia βάσει των θεμάτων και τα αποθηκεύει σε CSV.\n",
    "        :param topic_list: Λίστα με τα θέματα προς αναζήτηση στη Wikipedia.\n",
    "        \"\"\"\n",
    "        if os.path.exists(self.csv_file):\n",
    "            # Αν το αρχείο υπάρχει ήδη, αποφεύγεται η συλλογή δεδομένων\n",
    "            print(f\"File {self.csv_file} already exists. Skipping scraping.\")\n",
    "            return\n",
    "\n",
    "        with open(self.csv_file, 'w', encoding='utf-8', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(['doc_id', 'content'])  # Εισάγει κεφαλίδα στο αρχείο\n",
    "            doc_id = 1\n",
    "\n",
    "            for topic in topic_list:\n",
    "                # Δημιουργεί το URL για κάθε θέμα και κατεβάζει το περιεχόμενο\n",
    "                url = f\"{self.base_url}{topic}\"\n",
    "                print(f\"Scraping: {url}\")\n",
    "                response = requests.get(url)\n",
    "                if response.status_code == 200:\n",
    "                    # Εξάγει το περιεχόμενο των παραγράφων με BeautifulSoup\n",
    "                    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "                    paragraphs = soup.find_all('p')\n",
    "                    content = \" \".join([para.get_text() for para in paragraphs])\n",
    "                    if content.strip():  # Αποθηκεύει το περιεχόμενο αν δεν είναι κενό\n",
    "                        writer.writerow([doc_id, content])\n",
    "                        doc_id += 1\n",
    "                else:\n",
    "                    print(f\"Failed to retrieve: {url}\")\n",
    "\n",
    "        print(f\"Scraping complete. Data saved to {self.csv_file}\")\n",
    "\n",
    "\n",
    "class SearchEngine:\n",
    "    \"\"\"Κλάση μηχανής αναζήτησης για διαχείριση και αναζήτηση εγγράφων.\"\"\"\n",
    "    \n",
    "    def __init__(self, csv_file):\n",
    "        \"\"\"\n",
    "        Αρχικοποιεί τη μηχανή αναζήτησης.\n",
    "        :param csv_file: Το όνομα του αρχείου CSV που περιέχει τα έγγραφα.\n",
    "        \"\"\"\n",
    "        self.csv_file = csv_file\n",
    "        self.documents = {}\n",
    "        self.inverted_index = defaultdict(list)\n",
    "        self.stop_words = set(stopwords.words('english'))  # Φορτώνει τις stopwords\n",
    "        self.stemmer = PorterStemmer()  # Stemmer για την κανονικοποίηση\n",
    "        self.lemmatizer = WordNetLemmatizer()  # Lemmatizer για την κανονικοποίηση\n",
    "        self._load_documents()  # Φορτώνει τα έγγραφα από το CSV\n",
    "        self._build_inverted_index()  # Δημιουργεί το inverted index\n",
    "\n",
    "    def _load_documents(self):\n",
    "        \"\"\"\n",
    "        Φορτώνει τα έγγραφα από το αρχείο CSV και τα αποθηκεύει στο dictionary.\n",
    "        \"\"\"\n",
    "        if not os.path.exists(self.csv_file):\n",
    "            raise FileNotFoundError(f\"File {self.csv_file} does not exist.\")\n",
    "\n",
    "        with open(self.csv_file, 'r', encoding='utf-8') as file:\n",
    "            reader = csv.reader(file)\n",
    "            next(reader)  # Παραλείπει την κεφαλίδα\n",
    "            for row in reader:\n",
    "                doc_id, content = row[0], row[1]\n",
    "                self.documents[doc_id] = content\n",
    "\n",
    "    def _preprocess(self, text):\n",
    "        \"\"\"\n",
    "        Κανονικοποιεί το κείμενο με αφαίρεση ειδικών χαρακτήρων, tokenization, \n",
    "        φιλτράρισμα stopwords, και stemming/lemmatization.\n",
    "        :param text: Το κείμενο προς επεξεργασία.\n",
    "        :return: Λίστα κανονικοποιημένων tokens.\n",
    "        \"\"\"\n",
    "        text = ''.join(char for char in text if char.isalnum() or char.isspace())  # Αφαίρεση ειδικών χαρακτήρων\n",
    "        tokens = word_tokenize(text.lower())  # Tokenization και μετατροπή σε μικρά γράμματα\n",
    "        tokens = [token for token in tokens if token not in self.stop_words]  # Αφαίρεση stopwords\n",
    "        tokens = [self.stemmer.stem(self.lemmatizer.lemmatize(token)) for token in tokens]  # Εφαρμογή stemming και lemmatization\n",
    "        return tokens\n",
    "\n",
    "    def _build_inverted_index(self):\n",
    "        \"\"\"\n",
    "        Δημιουργεί το inverted index χρησιμοποιώντας τα tokens των εγγράφων.\n",
    "        \"\"\"\n",
    "        for doc_id, content in self.documents.items():\n",
    "            tokens = self._preprocess(content)\n",
    "            for token in set(tokens):  # Χρησιμοποιεί μοναδικά tokens για αποφυγή διπλών εισαγωγών\n",
    "                self.inverted_index[token].append(doc_id)\n",
    "\n",
    "    def search(self, query):\n",
    "        \"\"\"\n",
    "        Εκτελεί αναζήτηση στα έγγραφα βάσει του ερωτήματος.\n",
    "        :param query: Το ερώτημα αναζήτησης.\n",
    "        :return: Λίστα doc_ids που ταιριάζουν με το ερώτημα.\n",
    "        \"\"\"\n",
    "        query_tokens = self._preprocess(query)\n",
    "        if not query_tokens:\n",
    "            return []\n",
    "\n",
    "        doc_scores = defaultdict(int)  # Αποθηκεύει τις βαθμολογίες εγγράφων\n",
    "        for token in query_tokens:\n",
    "            if token in self.inverted_index:\n",
    "                for doc_id in self.inverted_index[token]:\n",
    "                    doc_scores[doc_id] += 1\n",
    "\n",
    "        # Επιστρέφει τα έγγραφα με ταξινόμηση βάσει της βαθμολογίας\n",
    "        sorted_docs = sorted(doc_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "        return [doc_id for doc_id, _ in sorted_docs]\n",
    "\n",
    "    def evaluate(self, test_queries, test_labels):\n",
    "        \"\"\"\n",
    "        Αξιολογεί τη μηχανή αναζήτησης χρησιμοποιώντας μετρικές precision, recall, και F1-score.\n",
    "        :param test_queries: Λίστα ερωτημάτων αναζήτησης.\n",
    "        :param test_labels: Λίστα με λίστες σχετικών doc_ids για κάθε ερώτημα.\n",
    "        :return: Precision, recall, και F1-score.\n",
    "        \"\"\"\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "\n",
    "        for query, relevant_docs in zip(test_queries, test_labels):\n",
    "            retrieved_docs = self.search(query)\n",
    "            y_true.extend([1 if doc in relevant_docs else 0 for doc in self.documents.keys()])\n",
    "            y_pred.extend([1 if doc in retrieved_docs else 0 for doc in self.documents.keys()])\n",
    "\n",
    "        precision = precision_score(y_true, y_pred, zero_division=0)\n",
    "        recall = recall_score(y_true, y_pred, zero_division=0)\n",
    "        f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "        return precision, recall, f1\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Enter Wikipedia topics separated by commas (e.g., Natural_language_processing,Python_(programming_language)):\")\n",
    "    user_input = input(\"Topics: \")\n",
    "    topics = [topic.strip() for topic in user_input.split(',') if topic.strip()]  # Επεξεργασία θεμάτων\n",
    "\n",
    "    if not topics:\n",
    "        print(\"No topics provided. Exiting.\")\n",
    "        exit()\n",
    "\n",
    "    scraper = WikipediaScraper(\"https://en.wikipedia.org/wiki/\", \"wikipedia_documents.csv\")\n",
    "    scraper.scrape(topics)\n",
    "\n",
    "    search_engine = SearchEngine('wikipedia_documents.csv')\n",
    "\n",
    "    test_queries = [\"machine learning\", \"neural networks\"]\n",
    "    test_labels = [[\"1\", \"2\"], [\"3\", \"4\"]]  # Δείγματα για αξιολόγηση\n",
    "    precision, recall, f1 = search_engine.evaluate(test_queries, test_labels)\n",
    "    print(f\"Evaluation Results - Precision: {precision}, Recall: {recall}, F1-score: {f1}\")\n",
    "\n",
    "    while True:\n",
    "        query = input(\"Enter your search query (or type 'exit' to quit): \")\n",
    "        if query.lower() == 'exit':\n",
    "            break\n",
    "        results = search_engine.search(query)\n",
    "        if results:\n",
    "            print(\"Documents found:\")\n",
    "            for doc_id in results:\n",
    "                print(f\"- {doc_id}: {search_engine.documents[doc_id][:1000]}...\")\n",
    "        else:\n",
    "            print(\"No documents found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1955b156",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca9d088",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a4020d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
